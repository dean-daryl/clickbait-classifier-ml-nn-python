{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46544882-74e1-4dda-87bc-7155ceea9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc366b4f-d9ff-481a-ae55-b4fbf0a5374a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import joblib\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64280f2e-4327-4444-9419-314fce704ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0 = pd.read_csv(\"input/clickbait_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8926447-b76a-486f-a50d-2d5aab7eba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                                 Should I Get Bings      1\n",
      "1      Which TV Female Friend Group Do You Belong In      1\n",
      "2  The New \"Star Wars: The Force Awakens\" Trailer...      1\n",
      "3  This Vine Of New York On \"Celebrity Big Brothe...      1\n",
      "4  A Couple Did A Stunning Photo Shoot With Their...      1\n",
      "(32000, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset0 = dataset0.rename(columns={\"headline\": \"text\", \"clickbait\": \"label\"})\n",
    "\n",
    "print(dataset0.head())\n",
    "print(dataset0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "624844c9-6681-451b-bfcc-114f001c883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                                          get bings      1\n",
      "1                      tv female friend group belong      1\n",
      "2      new star war force awakens trailer give chill      1\n",
      "3  vine new york celebrity big brother fucking pe...      1\n",
      "4  couple stunning photo shoot baby learning inop...      1\n"
     ]
    }
   ],
   "source": [
    "# pre process text ( remove punctuation, make characters lowercase and do lemmatization )\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove punctuation using regex\n",
    "    text = re.sub(rf\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "\n",
    "    # 3. Tokenize the text\n",
    "    words = text.split()\n",
    "\n",
    "    # 4. Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # 5. Lemmatize each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # 6. Join back into a string\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "df = dataset0.copy()\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_text)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5411d53-9655-400b-a6ae-076c43d6ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20480,)\n",
      "(6400,)\n"
     ]
    }
   ],
   "source": [
    "# Train/Test split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train_data into train/val\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e698b6d3-26b8-436f-848b-78433eef65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terms Frequency -  Inverse Document Frequency\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_data).toarray()\n",
    "X_val = vectorizer.transform(val_data).toarray()\n",
    "X_test = vectorizer.transform(test_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f6414f-d282-482e-b11a-24aee75f53b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.3707 - val_accuracy: 0.9473 - val_loss: 0.1442\n",
      "Epoch 2/7\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0593 - val_accuracy: 0.9438 - val_loss: 0.1573\n",
      "Epoch 3/7\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0356 - val_accuracy: 0.9445 - val_loss: 0.1820\n",
      "Epoch 4/7\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0225 - val_accuracy: 0.9406 - val_loss: 0.2097\n",
      "Epoch 5/7\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0130 - val_accuracy: 0.9387 - val_loss: 0.2388\n",
      "Epoch 6/7\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0097 - val_accuracy: 0.9408 - val_loss: 0.2819\n",
      "Epoch 7/7\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0061 - val_accuracy: 0.9428 - val_loss: 0.2935\n",
      "Accuracy: 0.9505\n",
      "F1-score: 0.9508\n",
      "Recall: 0.9358\n",
      "Precision: 0.9662\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# === Compile with default settings (no optimizer tuning)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# === Train model (no early stopping)\n",
    "model.fit(X_train, train_labels, validation_data=(X_val, val_labels), epochs=7)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "f1 = f1_score(test_labels, y_pred, zero_division=0)\n",
    "recall = recall_score(test_labels, y_pred, zero_division=0)\n",
    "precision = precision_score(test_labels, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "015fcaee-6c16-4b05-b412-7ae3e44b52a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to saved_models/nn_instance2.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_models/nn_instance1.h5\")\n",
    "print(\"Model saved to saved_models/nn_instance2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf211f1e-319e-4d64-b873-48dad067a2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7929 - loss: 1.0518 - val_accuracy: 0.9285 - val_loss: 0.5421\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.5346 - val_accuracy: 0.9252 - val_loss: 0.5051\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.5055 - val_accuracy: 0.9197 - val_loss: 0.4950\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.4882 - val_accuracy: 0.9297 - val_loss: 0.4820\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.4747 - val_accuracy: 0.9287 - val_loss: 0.4656\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.4681 - val_accuracy: 0.9191 - val_loss: 0.4957\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.4576 - val_accuracy: 0.9291 - val_loss: 0.4617\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.4395 - val_accuracy: 0.9342 - val_loss: 0.4369\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.4302 - val_accuracy: 0.9326 - val_loss: 0.4527\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.4368 - val_accuracy: 0.9309 - val_loss: 0.4427\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.4276 - val_accuracy: 0.9346 - val_loss: 0.4299\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9344 - loss: 0.4257 - val_accuracy: 0.9270 - val_loss: 0.4478\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.4120 - val_accuracy: 0.9340 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.3983 - val_accuracy: 0.9336 - val_loss: 0.4212\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.4026 - val_accuracy: 0.9354 - val_loss: 0.4129\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.3933 - val_accuracy: 0.9324 - val_loss: 0.4088\n",
      "Epoch 17/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 0.3919 - val_accuracy: 0.9348 - val_loss: 0.4128\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.3855 - val_accuracy: 0.9371 - val_loss: 0.3975\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.3852 - val_accuracy: 0.9342 - val_loss: 0.4097\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.3803 - val_accuracy: 0.9303 - val_loss: 0.4006\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step\n",
      "Accuracy: 0.9413\n",
      "F1-score: 0.9410\n",
      "Recall: 0.9166\n",
      "Precision: 0.9668\n",
      "Predicted labels: [0 0 1 ... 1 1 0]\n",
      "True labels: [0 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# build neural network model\n",
    "\n",
    "# Define model with regularization, dropout, deeper layers\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))  # Dropout added\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile with custom learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train with validation and early stopping\n",
    "model.fit(X_train, train_labels, validation_data=(X_val, val_labels), epochs=20, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "test_tfidf=  vectorizer.transform(test_data).toarray()\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "f1 = f1_score(test_labels, y_pred)\n",
    "recall = recall_score(test_labels, y_pred)\n",
    "precision = precision_score(test_labels, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Optional: Print predictions and true labels\n",
    "print(\"Predicted labels:\", y_pred.flatten())\n",
    "print(\"True labels:\", test_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49211a84-0ca8-4419-af1d-6daa0f552a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to saved_models/nn_instance2.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_models/nn_instance2.h5\")\n",
    "print(\"Model saved to saved_models/nn_instance2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f1d1f5-f1a7-4183-9107-6f0204c3139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(0.9940782448305989), 1: np.float64(1.0059927301306613)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.5858 - val_accuracy: 0.9381 - val_loss: 0.2348\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.2133 - val_accuracy: 0.9406 - val_loss: 0.2182\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1950 - val_accuracy: 0.9371 - val_loss: 0.2088\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1900 - val_accuracy: 0.9244 - val_loss: 0.2303\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1800 - val_accuracy: 0.9412 - val_loss: 0.2031\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1775 - val_accuracy: 0.9354 - val_loss: 0.1958\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9465 - loss: 0.1771 - val_accuracy: 0.9309 - val_loss: 0.2180\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1745 - val_accuracy: 0.9408 - val_loss: 0.1896\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1740 - val_accuracy: 0.9350 - val_loss: 0.2129\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1683 - val_accuracy: 0.9410 - val_loss: 0.1898\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1685 - val_accuracy: 0.9416 - val_loss: 0.1888\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9520 - loss: 0.1599 - val_accuracy: 0.9387 - val_loss: 0.1900\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1681 - val_accuracy: 0.9389 - val_loss: 0.1894\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1645 - val_accuracy: 0.9381 - val_loss: 0.1926\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step\n",
      "Accuracy: 0.9463\n",
      "F1-score: 0.9472\n",
      "Recall: 0.9435\n",
      "Precision: 0.9510\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# === Build the model ===\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# === Compile the model using RMSprop ===\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# === Early stopping ===\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# === Train the model ===\n",
    "history = model.fit(\n",
    "    X_train, train_labels,\n",
    "    validation_data=(X_val, val_labels),\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "f1 = f1_score(test_labels, y_pred, zero_division=0)\n",
    "recall = recall_score(test_labels, y_pred, zero_division=0)\n",
    "precision = precision_score(test_labels, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfda0c88-de71-41f4-b029-b86e9e935b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to saved_models/nn_instance3.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_models/nn_instance3.h5\")\n",
    "print(\"Model saved to saved_models/nn_instance3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23091c6-71b7-4061-b080-99994173e09d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# === Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# === Compile with SGD optimizer\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# === Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "# === Train the model\n",
    "history = model.fit(\n",
    "    X_train, train_labels,\n",
    "    validation_data=(X_val, val_labels),\n",
    "    epochs=30,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "f1 = f1_score(test_labels, y_pred, zero_division=0)\n",
    "recall = recall_score(test_labels, y_pred, zero_division=0)\n",
    "precision = precision_score(test_labels, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a75fab40-0600-40d0-8ec6-1865f763e521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to saved_models/nn_instance4.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_models/nn_instance4.h5\")\n",
    "print(\"Model saved to saved_models/nn_instance4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ecfb914-3a0d-4a6f-969a-54bc64308540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9505\n",
      "F1-score: 0.9508\n",
      "Recall: 0.9358\n",
      "Precision: 0.9662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Build the model\n",
    "logreg_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=1.0,  # Lower values = stronger regularization\n",
    "    solver='liblinear'  # Good for small datasets and binary classification\n",
    ")\n",
    "\n",
    "# === Fit the model\n",
    "logreg_model.fit(X_train, train_labels)\n",
    "\n",
    "# === Predict\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# === Evaluate\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "f1 = f1_score(test_labels, y_pred, zero_division=0)\n",
    "recall = recall_score(test_labels, y_pred, zero_division=0)\n",
    "precision = precision_score(test_labels, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3babe5b3-ca9d-4cd9-923d-c17822430265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to saved_models/logreg_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(logreg_model, \"saved_models/logreg_model.pkl\")\n",
    "print(\"Model saved to saved_models/logreg_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
